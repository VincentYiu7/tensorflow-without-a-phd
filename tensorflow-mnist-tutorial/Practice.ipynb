{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "S2Xw8ywSZdf9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Entendendo um pouco do Google Colaboratory"
      ]
    },
    {
      "metadata": {
        "id": "nVkV53yUZIVC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8yiPZsSUZM5J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYulL-7vY8xq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VqXYHwe4ZESc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tR4hiqFyeXb1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ]
    },
    {
      "metadata": {
        "id": "D_Z_uzq9C1Gb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RCyI4HGzEwp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "TB_DIR = './Graph'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQyTEnbDZjUx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualizaremos o treinamento utilizando o Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "0WBohMzC-XDl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(TB_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8cY1PJheT30",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baixando e visualizando a base de dados"
      ]
    },
    {
      "metadata": {
        "id": "aSNJHVZVX7wQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train, test = tf.keras.datasets.mnist.load_data()\n",
        "mnist_x, mnist_y = train\n",
        "\n",
        "mnist_ds = tf.data.Dataset.from_tensor_slices(mnist_x)\n",
        "print(mnist_ds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3AfB_217eTPv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(1, 5):\n",
        "  plt.subplot(220+i)\n",
        "  plt.imshow(mnist_x[i], cmap=plt.get_cmap('gray'))\n",
        "  print(mnist_y[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPEzsBIixITM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CÃ³digo"
      ]
    },
    {
      "metadata": {
        "id": "0uMn4S3_xPz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_name = 'mnist_1.0'\n",
        "\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    tf.summary.image('image', features)\n",
        "    W = tf.Variable(tf.zeros([784, 10]))\n",
        "    b = tf.Variable(tf.zeros([10]))\n",
        "    XX = tf.reshape(features, [-1, 784])\n",
        "\n",
        "    # The model\n",
        "    Y = tf.nn.softmax(tf.matmul(XX, W) + b)\n",
        "    \n",
        "    tf.summary.histogram(W.name, W)\n",
        "    tf.summary.histogram(b.name, b)\n",
        "        \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "        # loss function\n",
        "        cross_entropy = -tf.reduce_sum(tf.one_hot(labels, 10) * tf.log(Y))\n",
        "        # % of correct answers found in batch\n",
        "        predictions = tf.argmax(Y,1)\n",
        "        accuracy = tf.metrics.accuracy(predictions, labels)\n",
        "\n",
        "        evalmetrics = {\"accuracy/mnist\": accuracy}\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            tf.summary.scalar(\"accuracy/mnist\", accuracy[1])\n",
        "            tf.summary.scalar(\"learning_rate\", params[\"learning_rate\"])\n",
        "            optimizer = tf.train.GradientDescentOptimizer(params[\"learning_rate\"])\n",
        "            train_step = optimizer.minimize(cross_entropy,\n",
        "                                            global_step=tf.train.get_global_step())\n",
        "        else:\n",
        "            train_step = None\n",
        "    else:\n",
        "        cross_entropy = None\n",
        "        train_step = None\n",
        "        evalmetrics = None\n",
        "\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "            mode=mode,\n",
        "            predictions={\"classid\": predictions},\n",
        "            loss=cross_entropy,\n",
        "            train_op=train_step,\n",
        "            eval_metric_ops=evalmetrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugnLqp9axHwu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_input_fn(mnist_x, mnist_y, batch_size, mode, shuffle=False):\n",
        "    def _input_fn():\n",
        "        ds = tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(tf.expand_dims(mnist_x, -1), tf.float32)/256.0, \n",
        "            tf.cast(mnist_y, tf.int32)))\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            num_epochs = None # indefinitely\n",
        "        else:\n",
        "            num_epochs = 1 # end-of-input after this\n",
        "        if shuffle or mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            ds = ds.shuffle(5000).repeat(num_epochs).batch(batch_size)\n",
        "        else:\n",
        "            ds = ds.repeat(num_epochs).batch(batch_size)\n",
        "        ds = ds.prefetch(2)\n",
        "        return ds\n",
        "    return _input_fn\n",
        "\n",
        "\n",
        "def train_and_evaluate(model_dir, hparams):\n",
        "    \n",
        "    estimator = tf.estimator.Estimator(\n",
        "        model_fn = model_fn,\n",
        "        params = hparams,\n",
        "        config= tf.estimator.RunConfig(\n",
        "            save_checkpoints_steps = 1000,\n",
        "            log_step_count_steps=500\n",
        "            ),\n",
        "        model_dir = model_dir)\n",
        "    \n",
        "    train, test = tf.keras.datasets.mnist.load_data()\n",
        "    \n",
        "    train_x, train_y = train\n",
        "    train_spec = tf.estimator.TrainSpec(\n",
        "        input_fn = make_input_fn(\n",
        "            train_x, train_y,\n",
        "            hparams['batch_size'],\n",
        "            mode = tf.estimator.ModeKeys.TRAIN),\n",
        "        max_steps = (50000//hparams[\"batch_size\"]) * 20)\n",
        "    \n",
        "    test_x, test_y = test\n",
        "    eval_spec = tf.estimator.EvalSpec(\n",
        "        input_fn = make_input_fn(\n",
        "            test_x, test_y,\n",
        "            hparams['batch_size'],\n",
        "            mode = tf.estimator.ModeKeys.EVAL\n",
        "        ),\n",
        "        start_delay_secs = 1,\n",
        "        throttle_secs = 1\n",
        "    )\n",
        "\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-b5961EBS4HH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "params = {\n",
        "    \"batch_size\": 100,\n",
        "    \"learning_rate\": 0.003,\n",
        "    \"pkeep\": 0.75\n",
        "}\n",
        "\n",
        "train_and_evaluate(os.path.join(TB_DIR, model_name), params)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}